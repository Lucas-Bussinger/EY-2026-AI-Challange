{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14454523-9317-4174-80b5-ddfa81f17104",
   "metadata": {},
   "source": [
    "## 2026 EY AI & Data Challenge - Landsat Data Extraction Notebook\n",
    "\n",
    "This notebook demonstrates Landsat data extraction and the creation of an output file to be used by the benchmark notebook. The baseline data is [Landsat Collection 2 Level 2](https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2) data from the MS Planetary Computer catalog. \n",
    "\n",
    "<b>Caution</b> ... This notebook requires significant execution time as there are 9319 data points (unique locations and times) used for data extraction from the Landsat archive. The code takes about 7 hours to run to completion on a typical laptop computer and typical internet connection. Lower execution times are likely possible with optimization of the data extraction process and use of cloud computing services. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf044936-9aad-4300-a873-ddf8d2b43835",
   "metadata": {},
   "source": [
    "### Load Python Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a09f2097-d79a-4a87-9977-79a85b8e651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Planetary Computer tools for STAC API access and authentication\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "from odc.stac import stac_load\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78b8ac3-e803-471a-b3bd-d7d2ec5de930",
   "metadata": {},
   "source": [
    "<h3>Extracting Landsat Data Using API Calls</h3> <p align=\"justify\"> The API-based method allows us to efficiently access <b>Landsat</b> data for specific coordinates and time periods, ensuring scalability and reproducibility of the process. </p> <p align=\"justify\"> Through the API, we can query individual bands or compute indices like <b>NDMI</b> on-the-fly. This approach reduces storage requirements and simplifies data preprocessing, making it ideal for large-scale environmental and water quality analysis. </p>\n",
    "\n",
    "<p>The <b>compute_Landsat_values</b> function extracts Landsat surface reflectance values for specific sampling locations using a 100 m focal buffer around each point. For each location:</p>\n",
    "\n",
    "<ul>\n",
    "  <li>A bounding box (bbox) is created around the latitude and longitude coordinates.</li>\n",
    "  <li>The Microsoft Planetary Computer API is queried for Landsat-8 Level-2 surface reflectance imagery within the date range.</li>\n",
    "  <li>The nearest low-cloud (<10% cloud cover) scene is selected, and the specified bands (<b>green</b>, <b>nir08</b>, <b>swir16</b>, <b>swir22</b>) are loaded.</li>\n",
    "  <li>Median values of the pixels within the bounding box are computed to reduce the effect of noise or outliers.</li>\n",
    "</ul>\n",
    "\n",
    "<p><b>Why the buffer value is 0.00089831:</b></p>\n",
    "\n",
    "<p>We want a ~100 m buffer around each point. At the equator, 1 degree ‚âà 110 km. Therefore, the degree equivalent of 100 m is:</p>\n",
    "\n",
    "<p style=\"text-align:center;\">\n",
    "  <em>buffer_deg = 100 m / 110,000 m/deg ‚âà 0.00089831</em>\n",
    "</p>\n",
    "\n",
    "<p>This slightly adjusted value ensures that the buffer approximately matches the pixel resolution of Landsat imagery, capturing a ~100 m area around each sampling location.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "089b8e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "# Configura√ß√£o para tornar o GDAL mais resiliente a erros de rede\n",
    "import os\n",
    "os.environ[\"GDAL_HTTP_MAX_RETRY\"] = \"3\"\n",
    "os.environ[\"GDAL_HTTP_RETRY_DELAY\"] = \"5\"\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcd447c8-2951-4391-a5c8-916ce9666306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Landsat_values(row, max_retries=3):\n",
    "    # Colunas de sa√≠da para o Machine Learning\n",
    "    output_cols = [\n",
    "        \"w_coastal\", \"w_blue\", \"w_green\", \"w_red\", \"w_lwir11\", \"w_mndwi\", \"w_clorofila\", \"w_turbid_ndti\",\n",
    "        \"l_nir\", \"l_swir16\", \"l_swir22\", \"l_ndvi\", \"l_ndmi\", \"platform\", \"diff_days\", \"collection\"\n",
    "    ]\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # 1. CONVERS√ÉO DE TIPOS (Evita o erro do np.float64)\n",
    "            lat = float(row['Latitude'])\n",
    "            lon = float(row['Longitude'])\n",
    "            sample_dt = pd.to_datetime(row['Sample Date'], dayfirst=True, errors='coerce')\n",
    "            \n",
    "            if pd.isna(sample_dt):\n",
    "                return pd.Series({k: np.nan for k in output_cols})\n",
    "\n",
    "            # 2. CONFIGURA√á√ÉO DA GEOMETRIA E TEMPO\n",
    "            # Usamos Point para a busca (mais preciso) e BBox para o download (√°rea)\n",
    "            geometry = {\"type\": \"Point\", \"coordinates\": [lon, lat]}\n",
    "            \n",
    "            bbox_size = 0.03\n",
    "            bbox = [lon - bbox_size/2, lat - bbox_size/2, lon + bbox_size/2, lat + bbox_size/2]\n",
    "\n",
    "            # Janela de +- 60 dias (Garante dados mesmo em buracos de cobertura de 2011)\n",
    "            start_date = sample_dt - pd.Timedelta(days=60)\n",
    "            end_date = sample_dt + pd.Timedelta(days=60)\n",
    "            time_window = f\"{start_date.strftime('%Y-%m-%d')}/{end_date.strftime('%Y-%m-%d')}\"\n",
    "\n",
    "            # 3. BUSCA \"NUCLEAR\" (Sem filtros restritivos)\n",
    "            catalog = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "            \n",
    "            search = catalog.search(\n",
    "                collections=[\"landsat-c2-l2\", \"landsat-c2-l1\"], # Trazemos tudo o que tiver\n",
    "                intersects=geometry, # Busca por Ponto √© mais segura que BBox\n",
    "                datetime=time_window\n",
    "                # Sem query de nuvem ou plataforma aqui. Filtramos depois.\n",
    "            )\n",
    "            \n",
    "            items = search.item_collection()\n",
    "            \n",
    "            if len(items) == 0:\n",
    "                # Se falhar com Point, √© porque realmente n√£o existe nada num raio de 60 dias\n",
    "                return pd.Series({k: np.nan for k in output_cols})\n",
    "\n",
    "            # 4. ORDENA√á√ÉO E SELE√á√ÉO INTELIGENTE\n",
    "            # Calculamos a dist√¢ncia em dias para cada item encontrado\n",
    "            sample_date_utc = sample_dt.tz_localize(\"UTC\") if sample_dt.tzinfo is None else sample_dt.tz_convert(\"UTC\")\n",
    "            \n",
    "            # Ordena pelo item mais pr√≥ximo temporalmente\n",
    "            selected_item = sorted(items, key=lambda x: abs(x.datetime.replace(tzinfo=pd.Timestamp(x.datetime).tzinfo or \"UTC\") - sample_date_utc))[0]\n",
    "            \n",
    "            # Extra√ß√£o de Metadados\n",
    "            platform = selected_item.properties.get(\"platform\", \"unknown\")\n",
    "            coll_id = \"L2\" if \"c2-l2\" in selected_item.collection_id else \"L1\"\n",
    "            diff_days = abs((selected_item.datetime.replace(tzinfo=None) - sample_dt.replace(tzinfo=None)).days)\n",
    "\n",
    "            # 5. MAPEAMENTO DE BANDAS (Corre√ß√£o Definitiva para T√©rmica)\n",
    "            assets = selected_item.assets.keys()\n",
    "            mapping = {\n",
    "                \"blue\": \"blue\", \"green\": \"green\", \"red\": \"red\",\n",
    "                \"swir16\": \"swir16\", \"swir22\": \"swir22\", \"qa_pixel\": \"qa_pixel\"\n",
    "            }\n",
    "            \n",
    "            # --- CORRE√á√ÉO DA BANDA NIR ---\n",
    "            # Se n√£o tiver nir08 (L8), tenta nir (L5/L7)\n",
    "            mapping[\"nir\"] = \"nir08\" if \"nir08\" in assets else \"nir\"\n",
    "\n",
    "            # --- CORRE√á√ÉO DA BANDA T√âRMICA ---\n",
    "            # Procuramos qual nome de banda t√©rmica existe neste item espec√≠fico\n",
    "            # st_b6 = Surface Temperature (Landsat 5/7 Level 2)\n",
    "            # lwir11 = Landsat 8/9\n",
    "            # lwir = Landsat 5/7 Level 1\n",
    "            thermal_candidates = [\"lwir11\", \"st_b6\", \"lwir\", \"lwir60\"]\n",
    "            \n",
    "            thermal_band_found = None\n",
    "            for cand in thermal_candidates:\n",
    "                if cand in assets:\n",
    "                    thermal_band_found = cand\n",
    "                    break\n",
    "            \n",
    "            if thermal_band_found:\n",
    "                mapping[\"lwir11\"] = thermal_band_found\n",
    "            else:\n",
    "                # Se n√£o achar nenhuma t√©rmica, removemos do mapping para n√£o quebrar o download\n",
    "                # O valor ficar√° NaN depois\n",
    "                pass\n",
    "\n",
    "            # Banda Coastal (S√≥ existe no L8/L9)\n",
    "            if \"coastal\" in assets: mapping[\"coastal\"] = \"coastal\"\n",
    "\n",
    "            # 6. DOWNLOAD (STAC LOAD)\n",
    "            # Passamos apenas as bandas que realmente existem no mapping\n",
    "            bands_to_load = list(mapping.values())\n",
    "            \n",
    "            data = stac_load(\n",
    "                [selected_item], \n",
    "                bands=bands_to_load, \n",
    "                bbox=bbox, \n",
    "                patch_url=pc.sign_url, \n",
    "                crs=\"EPSG:4326\", \n",
    "                resolution=0.00027\n",
    "            ).compute().isel(time=0)\n",
    "\n",
    "            # 7. ESCALONAMENTO E CORRE√á√ÉO DE VALORES\n",
    "            bands_spectral = [b for b in [\"blue\", \"green\", \"red\", \"nir\", \"swir16\", \"swir22\", \"coastal\"] if b in mapping]\n",
    "            \n",
    "            if coll_id == \"L2\":\n",
    "                # Fatores oficiais para Collection 2 Level 2 (Reflet√¢ncia)\n",
    "                for b in bands_spectral:\n",
    "                    if mapping[b] in data: # Seguran√ßa extra\n",
    "                         data[mapping[b]] = (data[mapping[b]] * 0.0000275) - 0.2\n",
    "                \n",
    "                # T√©rmica L2 (Seja lwir11 ou st_b6, a f√≥rmula Kelvin √© a mesma na Collection 2)\n",
    "                if \"lwir11\" in mapping and mapping[\"lwir11\"] in data:\n",
    "                    data[mapping[\"lwir11\"]] = (data[mapping[\"lwir11\"]] * 0.00341802 + 149.0) - 273.15\n",
    "                \n",
    "            else: # Level 1 (Fallback)\n",
    "                for b in bands_spectral:\n",
    "                    if mapping[b] in data:\n",
    "                        data[mapping[b]] = data[mapping[b]] / 65535.0\n",
    "                \n",
    "                if \"lwir11\" in mapping and mapping[\"lwir11\"] in data:\n",
    "                     data[mapping[\"lwir11\"]] = (data[mapping[\"lwir11\"]] * 0.00341802 + 149.0) - 273.15\n",
    "                     \n",
    "            # 8. M√ÅSCARAS E √çNDICES\n",
    "            \n",
    "            qa = data[mapping[\"qa_pixel\"]]\n",
    "\n",
    "            # A. Defini√ß√£o do que √© \"Ruim\" (Nuvens, Sombras e Bordas)\n",
    "            # Bit 1: Dilated Cloud (Bordas)\n",
    "            # Bit 3: Cloud (Nuvem)\n",
    "            # Bit 4: Cloud Shadow (Sombra)\n",
    "            # Usamos a opera√ß√£o bitwise OR (|) para juntar todos os problemas\n",
    "            cloud_mask = (qa & (1 << 3)) > 0\n",
    "            shadow_mask = (qa & (1 << 4)) > 0\n",
    "            dilated_mask = (qa & (1 << 1)) > 0\n",
    "            \n",
    "            # Se for L8 ou L9, removemos tamb√©m Cirrus (Bit 2)\n",
    "            cirrus_mask = (qa & (1 << 2)) > 0 if \"nir08\" in mapping.values() else False\n",
    "            \n",
    "            # M√°scara de Exclus√£o Total: Qualquer pixel que tenha um desses problemas\n",
    "            all_bad_pixels = cloud_mask | shadow_mask | dilated_mask | cirrus_mask\n",
    "\n",
    "            # B. Defini√ß√£o do que √© √Ågua (Candidatos)\n",
    "            # Usamos Bit 7 (Water) OU MNDWI > 0 (para pegar rios que o QA perdeu)\n",
    "            qa_is_water = (qa & (1 << 7)) > 0\n",
    "            \n",
    "            # Calculamos MNDWI com seguran√ßa (evitando divis√£o por zero)\n",
    "            # Adicionamos um valor √≠nfimo (1e-6) para n√£o dar erro se a soma for 0\n",
    "            mndwi_num = data[mapping[\"green\"]] - data[mapping[\"swir16\"]]\n",
    "            mndwi_den = data[mapping[\"green\"]] + data[mapping[\"swir16\"]] + 1e-6\n",
    "            mndwi = mndwi_num / mndwi_den\n",
    "            \n",
    "            # Candidato a √°gua: MNDWI positivo ou QA diz que √© √°gua\n",
    "            water_candidate = (mndwi > 0.0) | qa_is_water\n",
    "\n",
    "            # C. FILTRAGEM FINAL (A √Ågua Limpa)\n",
    "            # √â √°gua E N√ÉO TEM nuvem/sombra\n",
    "            is_water_clean = water_candidate & (~all_bad_pixels)\n",
    "            \n",
    "            # D. FILTRAGEM FINAL (A Terra Limpa)\n",
    "            # N√£o √© √°gua E N√ÉO TEM nuvem/sombra\n",
    "            is_land_clean = (~water_candidate) & (~all_bad_pixels)\n",
    "\n",
    "            # E. C√°lculo dos √çndices (S√≥ calculamos, o filtro vem na m√©dia)\n",
    "            # Adicionamos 1e-6 para evitar divis√£o por zero\n",
    "            ndvi = (data[mapping[\"nir\"]] - data[mapping[\"red\"]]) / (data[mapping[\"nir\"]] + data[mapping[\"red\"]] + 1e-6)\n",
    "            ndmi = (data[mapping[\"nir\"]] - data[mapping[\"swir16\"]]) / (data[mapping[\"nir\"]] + data[mapping[\"swir16\"]] + 1e-6)\n",
    "            ndti = (data[mapping[\"red\"]] - data[mapping[\"green\"]]) / (data[mapping[\"red\"]] + data[mapping[\"green\"]] + 1e-6)\n",
    "            clorofila = data[mapping[\"nir\"]] / (data[mapping[\"blue\"]] + 1e-6)\n",
    "            \n",
    "            # 9. EXTRA√á√ÉO DE M√âDIAS\n",
    "            def get_mean(da, mask):\n",
    "                # Aplica a m√°scara: Onde a m√°scara for False, vira NaN\n",
    "                vals = da.where(mask)\n",
    "                \n",
    "                # Conta quantos pixels v√°lidos sobraram\n",
    "                valid_pixels = vals.count().item()\n",
    "                \n",
    "                # Se n√£o sobrou nenhum pixel (ex: dia totalmente nublado em cima do rio), retorna NaN\n",
    "                if valid_pixels == 0:\n",
    "                    return np.nan\n",
    "                \n",
    "                return float(vals.mean().item())\n",
    "\n",
    "            return pd.Series({\n",
    "                # Features de √Ågua (Usando is_water_clean)\n",
    "                \"w_coastal\": get_mean(data[mapping[\"coastal\"]], is_water_clean) if \"coastal\" in mapping else np.nan,\n",
    "                \"w_blue\": get_mean(data[mapping[\"blue\"]], is_water_clean),\n",
    "                \"w_green\": get_mean(data[mapping[\"green\"]], is_water_clean),\n",
    "                \"w_red\": get_mean(data[mapping[\"red\"]], is_water_clean),\n",
    "                \"w_lwir11\": get_mean(data[mapping[\"lwir11\"]], is_water_clean),\n",
    "                \"w_mndwi\": get_mean(mndwi, is_water_clean),\n",
    "                \"w_clorofila\": get_mean(clorofila, is_water_clean),\n",
    "                \"w_turbid_ndti\": get_mean(ndti, is_water_clean),\n",
    "                \n",
    "                # Features de Terra (Usando is_land_clean)\n",
    "                \"l_nir\": get_mean(data[mapping[\"nir\"]], is_land_clean),\n",
    "                \"l_swir16\": get_mean(data[mapping[\"swir16\"]], is_land_clean),\n",
    "                \"l_swir22\": get_mean(data[mapping[\"swir22\"]], is_land_clean),\n",
    "                \"l_ndvi\": get_mean(ndvi, is_land_clean),\n",
    "                \"l_ndmi\": get_mean(ndmi, is_land_clean),\n",
    "                \n",
    "                # Metadados\n",
    "                \"platform\": platform,\n",
    "                \"diff_days\": diff_days,\n",
    "                \"collection\": coll_id,\n",
    "                \"pixels_water\": int(is_water_clean.sum().item()) # √ötil para saber se pegou √°gua suficiente\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            # Tratamento de erro 403/429 (Rate Limit)\n",
    "            if \"403\" in str(e) or \"429\" in str(e):\n",
    "                time.sleep(10) # Espera maior se for rate limit\n",
    "                continue\n",
    "            elif attempt < max_retries:\n",
    "                time.sleep( attempt* 2**3) # Espera antes de tentar novamente\n",
    "                continue\n",
    "            \n",
    "            print(f\"Erro Linha {row.name} (Lat:{row['Latitude']}, Lon:{row['Longitude']}): {e}\")\n",
    "            return pd.Series({k: np.nan for k in output_cols})\n",
    "\n",
    "    return pd.Series({k: np.nan for k in output_cols})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a4ea22-9d2a-4866-bc59-bf3962ecfe1a",
   "metadata": {},
   "source": [
    "### Extracting features for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c046f70-aa61-4bbe-8b1a-ac8624f87ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Total Alkalinity</th>\n",
       "      <th>Electrical Conductance</th>\n",
       "      <th>Dissolved Reactive Phosphorus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.760833</td>\n",
       "      <td>17.730278</td>\n",
       "      <td>02-01-2011</td>\n",
       "      <td>128.912</td>\n",
       "      <td>555.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26.861111</td>\n",
       "      <td>28.884722</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>74.720</td>\n",
       "      <td>162.9</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.450000</td>\n",
       "      <td>28.085833</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>89.254</td>\n",
       "      <td>573.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-27.671111</td>\n",
       "      <td>27.236944</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>82.000</td>\n",
       "      <td>203.6</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-27.356667</td>\n",
       "      <td>27.286389</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>56.100</td>\n",
       "      <td>145.1</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date  Total Alkalinity  Electrical Conductance  \\\n",
       "0 -28.760833  17.730278  02-01-2011           128.912                   555.0   \n",
       "1 -26.861111  28.884722  03-01-2011            74.720                   162.9   \n",
       "2 -26.450000  28.085833  03-01-2011            89.254                   573.0   \n",
       "3 -27.671111  27.236944  03-01-2011            82.000                   203.6   \n",
       "4 -27.356667  27.286389  03-01-2011            56.100                   145.1   \n",
       "\n",
       "   Dissolved Reactive Phosphorus  \n",
       "0                           10.0  \n",
       "1                          163.0  \n",
       "2                           80.0  \n",
       "3                          101.0  \n",
       "4                          151.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Water_Quality_df=pd.read_csv('water_quality_training_dataset.csv')\n",
    "Water_Quality_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f33406f9-9c07-400b-95a5-cdfdc81c5eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9319, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Water_Quality_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "040d1cb4-b620-4c44-aea4-cf8112a86d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Water_Quality_df_10 = Water_Quality_df.loc[665:677]\n",
    "Water_Quality_df_200 = Water_Quality_df.loc[0:199]\n",
    "Water_Quality_df_200.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9107ba-927e-4e8f-b108-b87f69336c80",
   "metadata": {},
   "source": [
    "<h3>Note:</h3>\n",
    "<p>The Landsat data extraction process for all 9,319 locations typically requires 7+ hours when executed in a single run. During long executions, you may occasionally encounter API limits, timeout errors, or request failures. To avoid these interruptions, we recommend running the extraction in smaller batches.</p>\n",
    "\n",
    "<p>In this notebook, we provide a sample code snippet demonstrating how to extract data for the first 200 locations. Participants are encouraged to follow the same batching approach to extract data for all 9,319 locations safely and efficiently.</p>\n",
    "\n",
    "<p>We have already executed the full extraction for all 9,319 locations and saved the output to <b>landsat_features_training.csv</b>, which will be used in the benchmark notebook.\n",
    "Similarly, participants can extract Landsat features in batches, combine the batch outputs, and save the final merged dataset as <b>landsat_features_training.csv</b> to ensure the benchmark notebook runs smoothly.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aebdaac4-88e2-49de-b5f1-f288af689406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running Landsat feature extraction for training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [01:19<00:00,  6.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# Extract band values from Landsat for training dataset\n",
    "train_features_path = \"landsat_features_training_10.csv\"\n",
    "\n",
    "print(\"üöÄ Running Landsat feature extraction for training data...\")\n",
    "landsat_train_features = Water_Quality_df_10.progress_apply(compute_Landsat_values, axis=1)\n",
    "landsat_train_features.to_csv(train_features_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb347a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Iniciando extra√ß√£o total de 9319 linhas em lotes de 300...\n",
      "\n",
      "Processing Batch 1 / 32 (Rows 0 to 300)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 30/300 [01:45<14:23,  3.20s/it]"
     ]
    }
   ],
   "source": [
    "train_features_path = \"../Datasets/landsat_features_more_bands_separated_training.csv\"\n",
    "batch_size = 300\n",
    "total_rows = len(Water_Quality_df)\n",
    "\n",
    "print(f\"üöÄ Iniciando extra√ß√£o total de {total_rows} linhas em lotes de {batch_size}...\")\n",
    "\n",
    "# Se quiser come√ßar do zero, remove o arquivo antigo\n",
    "if os.path.exists(train_features_path):\n",
    "    os.remove(train_features_path)\n",
    "\n",
    "# Loop pelos √≠ndices (sem tqdm aqui no range, para n√£o duplicar barras)\n",
    "for i in range(0, total_rows, batch_size):\n",
    "    \n",
    "    # 1. Seleciona o lote\n",
    "    batch = Water_Quality_df.iloc[i : i + batch_size]\n",
    "    \n",
    "    print(f\"\\nProcessing Batch {i // batch_size + 1} / {(total_rows // batch_size) + 1} (Rows {i} to {min(i + batch_size, total_rows)})...\")\n",
    "    \n",
    "    # 2. Aplica a fun√ß√£o com progress_apply (Isso mostra a barra por LINHA dentro do lote)\n",
    "    batch_results = batch.progress_apply(compute_Landsat_values, axis=1)\n",
    "    \n",
    "    # 3. Salva no CSV\n",
    "    # Se for o primeiro lote (i=0), escreve ('w') com cabe√ßalho\n",
    "    # Se forem os pr√≥ximos, anexa ('a') sem cabe√ßalho\n",
    "    if i == 0:\n",
    "        batch_results.to_csv(train_features_path, mode='w', index=False, header=True)\n",
    "    else:\n",
    "        batch_results.to_csv(train_features_path, mode='a', index=False, header=False)\n",
    "\n",
    "print(\"\\n‚úÖ Processamento conclu√≠do!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "303731e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Iniciando extra√ß√£o de 9319 linhas em blocos de 600...\n",
      "\n",
      "üì¶ Processando bloco 1 (linhas 0 at√© 599)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [28:34<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bloco 1 salvo com sucesso em: ../Datasets/landsat_features_more_bands_training.csv\n",
      "\n",
      "üì¶ Processando bloco 2 (linhas 600 at√© 1199)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [30:55<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bloco 2 salvo com sucesso em: ../Datasets/landsat_features_more_bands_training.csv\n",
      "\n",
      "üì¶ Processando bloco 3 (linhas 1200 at√© 1799)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [29:38<00:00,  2.96s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bloco 3 salvo com sucesso em: ../Datasets/landsat_features_more_bands_training.csv\n",
      "\n",
      "üì¶ Processando bloco 4 (linhas 1800 at√© 2399)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [29:09<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bloco 4 salvo com sucesso em: ../Datasets/landsat_features_more_bands_training.csv\n",
      "\n",
      "üì¶ Processando bloco 5 (linhas 2400 at√© 2999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 445/600 [20:39<05:19,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro na linha 2843: <!DOCTYPE html PUBLIC '-//W3C//DTD XHTML 1.0 Transitional//EN' 'http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd'>\n",
      "<html xmlns='http://www.w3.org/1999/xhtml'>\n",
      "\n",
      "<head>\n",
      "    <meta content='text/html; charset=utf-8' http-equiv='content-type' />\n",
      "    <style type='text/css'>\n",
      "        body {\n",
      "            font-family: Arial;\n",
      "            margin-left: 40px;\n",
      "        }\n",
      "\n",
      "        img {\n",
      "            border: 0 none;\n",
      "        }\n",
      "\n",
      "        #content {\n",
      "            margin-left: auto;\n",
      "            margin-right: auto\n",
      "        }\n",
      "\n",
      "        #message h1 {\n",
      "            font-size: 24px;\n",
      "            font-weight: normal;\n",
      "            color: #000000;\n",
      "            margin: 34px 0px 0px 0px\n",
      "        }\n",
      "\n",
      "        #message h2 {\n",
      "            font-size: 20px;\n",
      "            font-weight: normal;\n",
      "            color: #000000;\n",
      "            margin: 34px 0px 0px 0px\n",
      "        }\n",
      "\n",
      "        #message p {\n",
      "            font-size: 16px;\n",
      "            color: #000000;\n",
      "            margin: 8px 0px 0px 0px\n",
      "        }\n",
      "\n",
      "        #message hr {\n",
      "            margin: 15px 0px\n",
      "        }\n",
      "\n",
      "        #errorref {\n",
      "            font-size: 11px;\n",
      "            color: #737373;\n",
      "            margin-top: 41px\n",
      "        }\n",
      "    </style>\n",
      "    <title>Service unavailable</title>\n",
      "</head>\n",
      "\n",
      "<body>\n",
      "    <div id='content'>\n",
      "        <div id='message'>\n",
      "            <h1>502</h1>\n",
      "<h2><span>The service behind this page isn't responding to Azure Front Door.</span>\n",
      "</h2>\n",
      "<hr />\n",
      "<p>Bad Gateway</p>\n",
      "<p>Azure Front Door wasn't able to connect to the origin. <br> If the problem persists, use the troubleshooting steps to resolve the issue.</p>\n",
      "<br />\n",
      "<a href=\"https://learn.microsoft.com/en-us/azure/frontdoor/troubleshoot-issues\" target=\"blank\">Azure Documentation</a>\n",
      "<br />\n",
      "        </div>\n",
      "        <div id='errorref'>\n",
      "            <span>Error Info:</span><span>OriginConnectionAborted</span><br />\n",
      "<span>x-azure-ref ID:</span><span>20260131T204005Z-18677bdf6fbwrs5zhC1GRUadsg00000016qg000000006hnh            </span>\n",
      "        </div>\n",
      "    </div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [28:23<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bloco 5 salvo com sucesso em: ../Datasets/landsat_features_more_bands_training.csv\n",
      "\n",
      "üì¶ Processando bloco 6 (linhas 3000 at√© 3599)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [31:20<00:00,  3.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bloco 6 salvo com sucesso em: ../Datasets/landsat_features_more_bands_training.csv\n",
      "\n",
      "üì¶ Processando bloco 7 (linhas 3600 at√© 4199)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [34:47<00:00,  3.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bloco 7 salvo com sucesso em: ../Datasets/landsat_features_more_bands_training.csv\n",
      "\n",
      "üì¶ Processando bloco 8 (linhas 4200 at√© 4799)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [35:14<00:00,  3.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bloco 8 salvo com sucesso em: ../Datasets/landsat_features_more_bands_training.csv\n",
      "\n",
      "üì¶ Processando bloco 9 (linhas 4800 at√© 5399)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [35:08<00:00,  3.51s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bloco 9 salvo com sucesso em: ../Datasets/landsat_features_more_bands_training.csv\n",
      "\n",
      "üì¶ Processando bloco 10 (linhas 5400 at√© 5999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [35:57<00:00,  3.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bloco 10 salvo com sucesso em: ../Datasets/landsat_features_more_bands_training.csv\n",
      "\n",
      "üì¶ Processando bloco 11 (linhas 6000 at√© 6599)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 447/600 [26:23<07:09,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro na linha 6445: <!DOCTYPE html PUBLIC '-//W3C//DTD XHTML 1.0 Transitional//EN' 'http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd'>\n",
      "<html xmlns='http://www.w3.org/1999/xhtml'>\n",
      "\n",
      "<head>\n",
      "    <meta content='text/html; charset=utf-8' http-equiv='content-type' />\n",
      "    <style type='text/css'>\n",
      "        body {\n",
      "            font-family: Arial;\n",
      "            margin-left: 40px;\n",
      "        }\n",
      "\n",
      "        img {\n",
      "            border: 0 none;\n",
      "        }\n",
      "\n",
      "        #content {\n",
      "            margin-left: auto;\n",
      "            margin-right: auto\n",
      "        }\n",
      "\n",
      "        #message h1 {\n",
      "            font-size: 24px;\n",
      "            font-weight: normal;\n",
      "            color: #000000;\n",
      "            margin: 34px 0px 0px 0px\n",
      "        }\n",
      "\n",
      "        #message h2 {\n",
      "            font-size: 20px;\n",
      "            font-weight: normal;\n",
      "            color: #000000;\n",
      "            margin: 34px 0px 0px 0px\n",
      "        }\n",
      "\n",
      "        #message p {\n",
      "            font-size: 16px;\n",
      "            color: #000000;\n",
      "            margin: 8px 0px 0px 0px\n",
      "        }\n",
      "\n",
      "        #message hr {\n",
      "            margin: 15px 0px\n",
      "        }\n",
      "\n",
      "        #errorref {\n",
      "            font-size: 11px;\n",
      "            color: #737373;\n",
      "            margin-top: 41px\n",
      "        }\n",
      "    </style>\n",
      "    <title>Service unavailable</title>\n",
      "</head>\n",
      "\n",
      "<body>\n",
      "    <div id='content'>\n",
      "        <div id='message'>\n",
      "            <h1>502</h1>\n",
      "<h2><span>The service behind this page isn't responding to Azure Front Door.</span>\n",
      "</h2>\n",
      "<hr />\n",
      "<p>Bad Gateway</p>\n",
      "<p>Azure Front Door wasn't able to connect to the origin. <br> If the problem persists, use the troubleshooting steps to resolve the issue.</p>\n",
      "<br />\n",
      "<a href=\"https://learn.microsoft.com/en-us/azure/frontdoor/troubleshoot-issues\" target=\"blank\">Azure Documentation</a>\n",
      "<br />\n",
      "        </div>\n",
      "        <div id='errorref'>\n",
      "            <span>Error Info:</span><span>OriginConnectionAborted</span><br />\n",
      "<span>x-azure-ref ID:</span><span>20260201T000817Z-18677bdf6fb5726bhC1GRUwpcc00000016n000000000ruyn            </span>\n",
      "        </div>\n",
      "    </div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [35:41<00:00,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bloco 11 salvo com sucesso em: ../Datasets/landsat_features_more_bands_training.csv\n",
      "\n",
      "üì¶ Processando bloco 12 (linhas 6600 at√© 7199)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [34:18<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bloco 12 salvo com sucesso em: ../Datasets/landsat_features_more_bands_training.csv\n",
      "\n",
      "üì¶ Processando bloco 13 (linhas 7200 at√© 7799)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [36:30<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bloco 13 salvo com sucesso em: ../Datasets/landsat_features_more_bands_training.csv\n",
      "\n",
      "üì¶ Processando bloco 14 (linhas 7800 at√© 8399)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [36:52<00:00,  3.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bloco 14 salvo com sucesso em: ../Datasets/landsat_features_more_bands_training.csv\n",
      "\n",
      "üì¶ Processando bloco 15 (linhas 8400 at√© 8999)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [35:45<00:00,  3.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bloco 15 salvo com sucesso em: ../Datasets/landsat_features_more_bands_training.csv\n",
      "\n",
      "üì¶ Processando bloco 16 (linhas 9000 at√© 9318)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 319/319 [18:50<00:00,  3.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bloco 16 salvo com sucesso em: ../Datasets/landsat_features_more_bands_training.csv\n",
      "\n",
      "‚ú® Processamento conclu√≠do!\n"
     ]
    }
   ],
   "source": [
    "train_features_path = \"../Datasets/landsat_features_more_bands_training.csv\"\n",
    "chunk_size = 600\n",
    "\n",
    "print(f\"üöÄ Iniciando extra√ß√£o de {len(Water_Quality_df)} linhas em blocos de {chunk_size}...\")\n",
    "\n",
    "# O loop percorre o dataframe de 600 em 600\n",
    "for i in range(0, len(Water_Quality_df), chunk_size):\n",
    "    # Seleciona o bloco atual\n",
    "    subset = Water_Quality_df.iloc[i : i + chunk_size]\n",
    "    \n",
    "    print(f\"\\nüì¶ Processando bloco {i//chunk_size + 1} (linhas {i} at√© {i + len(subset) - 1})...\")\n",
    "    \n",
    "    # Aplica a fun√ß√£o no bloco atual\n",
    "    # Nota: usamos axis=1 para passar a linha inteira para a fun√ß√£o\n",
    "    chunk_features = subset.progress_apply(compute_Landsat_values, axis=1)\n",
    "    \n",
    "    # Verifica se o arquivo j√° existe para decidir se escreve o cabe√ßalho (header)\n",
    "    file_exists = os.path.isfile(train_features_path)\n",
    "    \n",
    "    # Salva o bloco atual no CSV (mode='a' √© para dar APPEND, ou seja, anexar ao final)\n",
    "    chunk_features.to_csv(\n",
    "        train_features_path, \n",
    "        mode='a', \n",
    "        index=False, \n",
    "        header=not file_exists, # S√≥ coloca o cabe√ßalho se o arquivo estiver sendo criado agora\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Bloco {i//chunk_size + 1} salvo com sucesso em: {train_features_path}\")\n",
    "    time.sleep(16)  # Pequena pausa entre blocos para evitar sobrecarga\n",
    "\n",
    "print(\"\\n‚ú® Processamento conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400e9ddb-81f6-45eb-ad41-e1950f6f4eac",
   "metadata": {},
   "source": [
    "<p><b>NDMI and MNDWI Indices:</b></p>\n",
    "<p>In this notebook, we compute two commonly used water-related indices from the extracted Landsat bands:</p>\n",
    "<ul>\n",
    "  <li><b>NDMI (Normalized Difference Moisture Index):</b> Measures vegetation water content and surface moisture. Computed as <em>(NIR - SWIR16) / (NIR + SWIR16)</em>.</li>\n",
    "  <li><b>MNDWI (Modified Normalized Difference Water Index):</b> Highlights open water features by enhancing water reflectance and suppressing built-up areas. Computed as <em>(Green - SWIR16) / (Green + SWIR16)</em>.</li>\n",
    "</ul>\n",
    "\n",
    "<p>An <b>epsilon value</b> (<em>eps = 1e-10</em>) is added in the denominators to avoid division by zero. These indices are widely used in hydrological and water quality analyses for detecting water presence and vegetation moisture levels.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce803dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9319, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landsat_train_features = pd.read_csv(train_features_path)\n",
    "landsat_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31ca3eaa-45f9-44af-b444-2dff934d02f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create indices: NDMI and MNDWI\n",
    "eps = 1e-10\n",
    "landsat_train_features['NDMI'] = (landsat_train_features['nir'] - landsat_train_features['swir16']) / (landsat_train_features['nir'] + landsat_train_features['swir16'] + eps)\n",
    "landsat_train_features['MNDWI'] = (landsat_train_features['green'] - landsat_train_features['swir16']) / (landsat_train_features['green'] + landsat_train_features['swir16'] + eps)\n",
    "landsat_train_features['Clorfilia'] = (landsat_train_features['green']/landsat_train_features['blue'] + eps)\n",
    "landsat_train_features['Turbidity'] = (landsat_train_features['red']/landsat_train_features['blue'] + eps)\n",
    "landsat_train_features['NDTI'] = (landsat_train_features['red'] - landsat_train_features['green']) / (landsat_train_features['red'] + landsat_train_features['green'] + eps)\n",
    "landsat_train_features[\"NDVI\"] = (landsat_train_features['nir'] - landsat_train_features['red']) / (landsat_train_features['nir'] + landsat_train_features['red'] + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d9d6711-3553-437a-8830-db69ce8afc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_train_features['Latitude'] = Water_Quality_df['Latitude']\n",
    "landsat_train_features['Longitude'] = Water_Quality_df['Longitude']\n",
    "landsat_train_features['Sample Date'] = Water_Quality_df['Sample Date']\n",
    "landsat_train_features = landsat_train_features[['Latitude', 'Longitude', 'Sample Date', 'nir', 'green', 'swir16', 'swir22', 'coastal',\n",
    "                                                 'blue', 'red', 'lwir11', 'NDMI', 'MNDWI', 'Clorfilia', 'Turbidity', 'NDTI', 'NDVI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb76690d-077e-4c1d-8213-4300c87f62cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_features_path = \"../Datasets/landsat_features_more_bands_final_training.csv\"\n",
    "landsat_train_features.to_csv(final_train_features_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f3ff058-cace-49ea-890c-a6a9e7ae43cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>nir</th>\n",
       "      <th>green</th>\n",
       "      <th>swir16</th>\n",
       "      <th>swir22</th>\n",
       "      <th>NDMI</th>\n",
       "      <th>MNDWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.760833</td>\n",
       "      <td>17.730278</td>\n",
       "      <td>02-01-2011</td>\n",
       "      <td>11190.0</td>\n",
       "      <td>11426.0</td>\n",
       "      <td>7687.5</td>\n",
       "      <td>7645.0</td>\n",
       "      <td>0.185538</td>\n",
       "      <td>0.195595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26.861111</td>\n",
       "      <td>28.884722</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>17658.5</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>13746.5</td>\n",
       "      <td>10574.0</td>\n",
       "      <td>0.124566</td>\n",
       "      <td>-0.180134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.450000</td>\n",
       "      <td>28.085833</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>15210.0</td>\n",
       "      <td>10720.0</td>\n",
       "      <td>17974.0</td>\n",
       "      <td>14201.0</td>\n",
       "      <td>-0.083293</td>\n",
       "      <td>-0.252805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-27.671111</td>\n",
       "      <td>27.236944</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>14887.0</td>\n",
       "      <td>10943.0</td>\n",
       "      <td>13522.0</td>\n",
       "      <td>11403.0</td>\n",
       "      <td>0.048048</td>\n",
       "      <td>-0.105416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-27.356667</td>\n",
       "      <td>27.286389</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>16828.5</td>\n",
       "      <td>9502.5</td>\n",
       "      <td>12665.5</td>\n",
       "      <td>9643.0</td>\n",
       "      <td>0.141147</td>\n",
       "      <td>-0.142683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date      nir    green   swir16   swir22  \\\n",
       "0 -28.760833  17.730278  02-01-2011  11190.0  11426.0   7687.5   7645.0   \n",
       "1 -26.861111  28.884722  03-01-2011  17658.5   9550.0  13746.5  10574.0   \n",
       "2 -26.450000  28.085833  03-01-2011  15210.0  10720.0  17974.0  14201.0   \n",
       "3 -27.671111  27.236944  03-01-2011  14887.0  10943.0  13522.0  11403.0   \n",
       "4 -27.356667  27.286389  03-01-2011  16828.5   9502.5  12665.5   9643.0   \n",
       "\n",
       "       NDMI     MNDWI  \n",
       "0  0.185538  0.195595  \n",
       "1  0.124566 -0.180134  \n",
       "2 -0.083293 -0.252805  \n",
       "3  0.048048 -0.105416  \n",
       "4  0.141147 -0.142683  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview File\n",
    "landsat_train_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a81367",
   "metadata": {},
   "source": [
    "### Joining data from the example data set with the downloaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfbbd657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas no seu original: 9319\n",
      "Linhas no exemplo: 9319\n",
      "Linhas ap√≥s a uni√£o: 9319\n"
     ]
    }
   ],
   "source": [
    "landsat_example_train_features = pd.read_csv('../Datasets/landsat_features_training.csv')\n",
    "landsat_train_features['Sample Date'] = pd.to_datetime(landsat_train_features['Sample Date'], dayfirst=True, errors='coerce')\n",
    "landsat_example_train_features['Sample Date'] = pd.to_datetime(landsat_example_train_features['Sample Date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# 2. Definir as colunas que servem de \"ID\" (as chaves)\n",
    "chaves = ['Latitude', 'Longitude', 'Sample Date']\n",
    "\n",
    "# 3. Fazer o merge (Outer Join)\n",
    "# how='outer' garante que:\n",
    "# - Se a linha s√≥ existe no seu, ela fica.\n",
    "# - Se a linha s√≥ existe no exemplo, ela fica.\n",
    "# - Se existe nos dois, elas se juntam.\n",
    "df_merged = pd.merge(\n",
    "    landsat_train_features, \n",
    "    landsat_example_train_features, \n",
    "    on=chaves, \n",
    "    how='outer', \n",
    "    suffixes=('', '_exemplo') # Adiciona sufixo nas colunas repetidas (nir, green, etc)\n",
    ")\n",
    "\n",
    "# 4. Lista das colunas que existem nos dois datasets\n",
    "colunas_comuns = ['nir', 'green', 'swir16', 'swir22', 'NDMI', 'MNDWI']\n",
    "\n",
    "# 5. Preencher os v√°zios: se a coluna original for NaN, pega o valor da coluna _exemplo\n",
    "for col in colunas_comuns:\n",
    "    df_merged[col] = df_merged[col].fillna(df_merged[col + '_exemplo'])\n",
    "\n",
    "df_merged = df_merged.sort_values(by=['Sample Date', 'Latitude', 'Longitude'])\n",
    "df_merged['Sample Date'] = df_merged['Sample Date'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "\n",
    "# 6. Agora que preenchemos, podemos apagar as colunas auxiliares do exemplo\n",
    "colunas_para_remover = [col + '_exemplo' for col in colunas_comuns]\n",
    "df_merged = df_merged.drop(columns=colunas_para_remover)\n",
    "\n",
    "# 7. Verificar o resultado\n",
    "print(f\"Linhas no seu original: {len(landsat_train_features)}\")\n",
    "print(f\"Linhas no exemplo: {len(landsat_example_train_features)}\")\n",
    "print(f\"Linhas ap√≥s a uni√£o: {len(df_merged)}\")\n",
    "\n",
    "# Salvar o resultado final\n",
    "df_merged.to_csv(\"../Datasets/landsat_features_more_bands_train_merged.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac5f5ea-bd8a-41bc-bb62-47cc952952bf",
   "metadata": {},
   "source": [
    "### Extracting features for the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb2adc08-4661-4fdc-a72d-78d34d37db73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Total Alkalinity</th>\n",
       "      <th>Electrical Conductance</th>\n",
       "      <th>Dissolved Reactive Phosphorus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-32.043333</td>\n",
       "      <td>27.822778</td>\n",
       "      <td>01-09-2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-33.329167</td>\n",
       "      <td>26.077500</td>\n",
       "      <td>16-09-2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32.991639</td>\n",
       "      <td>27.640028</td>\n",
       "      <td>07-05-2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-34.096389</td>\n",
       "      <td>24.439167</td>\n",
       "      <td>07-02-2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-32.000556</td>\n",
       "      <td>28.581667</td>\n",
       "      <td>01-10-2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date  Total Alkalinity  Electrical Conductance  \\\n",
       "0 -32.043333  27.822778  01-09-2014               NaN                     NaN   \n",
       "1 -33.329167  26.077500  16-09-2015               NaN                     NaN   \n",
       "2 -32.991639  27.640028  07-05-2015               NaN                     NaN   \n",
       "3 -34.096389  24.439167  07-02-2012               NaN                     NaN   \n",
       "4 -32.000556  28.581667  01-10-2014               NaN                     NaN   \n",
       "\n",
       "   Dissolved Reactive Phosphorus  \n",
       "0                            NaN  \n",
       "1                            NaN  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4                            NaN  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validation_df=pd.read_csv('submission_template.csv')\n",
    "Validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53ebf740-1917-4af1-b214-d60372f0ad0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validation_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fda679a5-9be5-4051-b6e2-5fe4a67aaa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running Landsat feature extraction for validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [10:38<00:00,  3.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# Extract band values from Landsat for submission dataset\n",
    "val_features_path = \"landsat_features_validation.csv\"\n",
    "\n",
    "print(\"üöÄ Running Landsat feature extraction for validation data...\")\n",
    "landsat_val_features = Validation_df.progress_apply(compute_Landsat_values, axis=1)\n",
    "landsat_val_features.to_csv(val_features_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d098354f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running Landsat feature extraction for validation data with more bands...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [13:29<00:00,  4.05s/it]\n"
     ]
    }
   ],
   "source": [
    "val_features_path = \"../Datasets/landsat_features_more_bands_validation.csv\"\n",
    "\n",
    "print(\"üöÄ Running Landsat feature extraction for validation data with more bands...\")\n",
    "landsat_val_features = Validation_df.progress_apply(compute_Landsat_values, axis=1)\n",
    "landsat_val_features.to_csv(val_features_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b130a364-1778-457e-ace5-b121dfcc7c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nir</th>\n",
       "      <th>green</th>\n",
       "      <th>swir16</th>\n",
       "      <th>swir22</th>\n",
       "      <th>coastal</th>\n",
       "      <th>blue</th>\n",
       "      <th>red</th>\n",
       "      <th>lwir11</th>\n",
       "      <th>NDMI</th>\n",
       "      <th>MNDWI</th>\n",
       "      <th>Clorfilia</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>NDTI</th>\n",
       "      <th>NDVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15229.0</td>\n",
       "      <td>12868.0</td>\n",
       "      <td>14797.0</td>\n",
       "      <td>12421.0</td>\n",
       "      <td>10961.0</td>\n",
       "      <td>11282.0</td>\n",
       "      <td>13210.0</td>\n",
       "      <td>39652.5</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>-0.069727</td>\n",
       "      <td>1.140578</td>\n",
       "      <td>1.170892</td>\n",
       "      <td>0.013115</td>\n",
       "      <td>0.070994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15081.0</td>\n",
       "      <td>9472.5</td>\n",
       "      <td>11916.0</td>\n",
       "      <td>9558.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8576.5</td>\n",
       "      <td>9311.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.117235</td>\n",
       "      <td>-0.114244</td>\n",
       "      <td>1.104472</td>\n",
       "      <td>1.085641</td>\n",
       "      <td>-0.008598</td>\n",
       "      <td>0.236553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9125.0</td>\n",
       "      <td>11100.5</td>\n",
       "      <td>9455.0</td>\n",
       "      <td>8711.0</td>\n",
       "      <td>8926.0</td>\n",
       "      <td>9504.0</td>\n",
       "      <td>11166.0</td>\n",
       "      <td>44180.5</td>\n",
       "      <td>-0.017761</td>\n",
       "      <td>0.080052</td>\n",
       "      <td>1.167982</td>\n",
       "      <td>1.174874</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>-0.100586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>20187.0</td>\n",
       "      <td>15329.0</td>\n",
       "      <td>18460.5</td>\n",
       "      <td>16786.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14179.0</td>\n",
       "      <td>15939.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044673</td>\n",
       "      <td>-0.092677</td>\n",
       "      <td>1.081106</td>\n",
       "      <td>1.124127</td>\n",
       "      <td>0.019509</td>\n",
       "      <td>0.117588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>15883.0</td>\n",
       "      <td>9083.5</td>\n",
       "      <td>12135.5</td>\n",
       "      <td>9484.0</td>\n",
       "      <td>7758.0</td>\n",
       "      <td>8045.0</td>\n",
       "      <td>8931.5</td>\n",
       "      <td>42839.5</td>\n",
       "      <td>0.133751</td>\n",
       "      <td>-0.143833</td>\n",
       "      <td>1.129086</td>\n",
       "      <td>1.110193</td>\n",
       "      <td>-0.008437</td>\n",
       "      <td>0.280139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>13619.5</td>\n",
       "      <td>10046.5</td>\n",
       "      <td>13105.0</td>\n",
       "      <td>10969.0</td>\n",
       "      <td>8424.0</td>\n",
       "      <td>8825.5</td>\n",
       "      <td>10108.0</td>\n",
       "      <td>45369.0</td>\n",
       "      <td>0.019252</td>\n",
       "      <td>-0.132108</td>\n",
       "      <td>1.138349</td>\n",
       "      <td>1.145318</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.147993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>13955.5</td>\n",
       "      <td>10670.0</td>\n",
       "      <td>17303.5</td>\n",
       "      <td>14835.5</td>\n",
       "      <td>9074.5</td>\n",
       "      <td>9505.0</td>\n",
       "      <td>11638.0</td>\n",
       "      <td>49183.5</td>\n",
       "      <td>-0.107105</td>\n",
       "      <td>-0.237135</td>\n",
       "      <td>1.122567</td>\n",
       "      <td>1.224408</td>\n",
       "      <td>0.043393</td>\n",
       "      <td>0.090550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         nir    green   swir16   swir22  coastal     blue      red   lwir11  \\\n",
       "0    15229.0  12868.0  14797.0  12421.0  10961.0  11282.0  13210.0  39652.5   \n",
       "1        NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2    15081.0   9472.5  11916.0   9558.5      NaN   8576.5   9311.0      NaN   \n",
       "3        NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "4     9125.0  11100.5   9455.0   8711.0   8926.0   9504.0  11166.0  44180.5   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "195  20187.0  15329.0  18460.5  16786.0      NaN  14179.0  15939.0      NaN   \n",
       "196  15883.0   9083.5  12135.5   9484.0   7758.0   8045.0   8931.5  42839.5   \n",
       "197  13619.5  10046.5  13105.0  10969.0   8424.0   8825.5  10108.0  45369.0   \n",
       "198  13955.5  10670.0  17303.5  14835.5   9074.5   9505.0  11638.0  49183.5   \n",
       "199      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "         NDMI     MNDWI  Clorfilia  Turbidity      NDTI      NDVI  \n",
       "0    0.014388 -0.069727   1.140578   1.170892  0.013115  0.070994  \n",
       "1         NaN       NaN        NaN        NaN       NaN       NaN  \n",
       "2    0.117235 -0.114244   1.104472   1.085641 -0.008598  0.236553  \n",
       "3         NaN       NaN        NaN        NaN       NaN       NaN  \n",
       "4   -0.017761  0.080052   1.167982   1.174874  0.002942 -0.100586  \n",
       "..        ...       ...        ...        ...       ...       ...  \n",
       "195  0.044673 -0.092677   1.081106   1.124127  0.019509  0.117588  \n",
       "196  0.133751 -0.143833   1.129086   1.110193 -0.008437  0.280139  \n",
       "197  0.019252 -0.132108   1.138349   1.145318  0.003051  0.147993  \n",
       "198 -0.107105 -0.237135   1.122567   1.224408  0.043393  0.090550  \n",
       "199       NaN       NaN        NaN        NaN       NaN       NaN  \n",
       "\n",
       "[200 rows x 14 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create indices: NDMI and MNDWI\n",
    "eps = 1e-10\n",
    "landsat_val_features['NDMI'] = (landsat_val_features['nir'] - landsat_val_features['swir16']) / (landsat_val_features['nir'] + landsat_val_features['swir16'] + eps)\n",
    "landsat_val_features['MNDWI'] = (landsat_val_features['green'] - landsat_val_features['swir16']) / (landsat_val_features['green'] + landsat_val_features['swir16'] + eps)\n",
    "landsat_val_features['Clorfilia'] = (landsat_val_features['green']/landsat_val_features['blue'] + eps)\n",
    "landsat_val_features['Turbidity'] = (landsat_val_features['red']/landsat_val_features['blue'] + eps)\n",
    "landsat_val_features['NDTI'] = (landsat_val_features['red'] - landsat_val_features['green']) / (landsat_val_features['red'] + landsat_val_features['green'] + eps)\n",
    "landsat_val_features[\"NDVI\"] = (landsat_val_features['nir'] - landsat_val_features['red']) / (landsat_val_features['nir'] + landsat_val_features['red'] + eps)\n",
    "landsat_val_features.to_csv(val_features_path, index=False)\n",
    "landsat_val_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc7fe05a-2bfd-4d0f-a796-48a1e2f3b3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_val_features['Latitude'] = Validation_df['Latitude']\n",
    "landsat_val_features['Longitude'] = Validation_df['Longitude']\n",
    "landsat_val_features['Sample Date'] = Validation_df['Sample Date']\n",
    "landsat_val_features = landsat_val_features[['Latitude', 'Longitude', 'Sample Date', 'nir', 'green', 'swir16', 'swir22', 'coastal',\n",
    "                                                 'blue', 'red', 'lwir11', 'NDMI', 'MNDWI', 'Clorfilia', 'Turbidity', 'NDTI', 'NDVI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "498c6e2f-a9f6-47a9-868b-7f80cd13ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_val_features.to_csv(val_features_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "001d2c58-1de5-4187-949e-e9c797de3331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>nir</th>\n",
       "      <th>green</th>\n",
       "      <th>swir16</th>\n",
       "      <th>swir22</th>\n",
       "      <th>coastal</th>\n",
       "      <th>blue</th>\n",
       "      <th>red</th>\n",
       "      <th>lwir11</th>\n",
       "      <th>NDMI</th>\n",
       "      <th>MNDWI</th>\n",
       "      <th>Clorfilia</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>NDTI</th>\n",
       "      <th>NDVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-32.043333</td>\n",
       "      <td>27.822778</td>\n",
       "      <td>01-09-2014</td>\n",
       "      <td>15229.0</td>\n",
       "      <td>12868.0</td>\n",
       "      <td>14797.0</td>\n",
       "      <td>12421.0</td>\n",
       "      <td>10961.0</td>\n",
       "      <td>11282.0</td>\n",
       "      <td>13210.0</td>\n",
       "      <td>39652.5</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>-0.069727</td>\n",
       "      <td>1.140578</td>\n",
       "      <td>1.170892</td>\n",
       "      <td>0.013115</td>\n",
       "      <td>0.070994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-33.329167</td>\n",
       "      <td>26.077500</td>\n",
       "      <td>16-09-2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32.991639</td>\n",
       "      <td>27.640028</td>\n",
       "      <td>07-05-2015</td>\n",
       "      <td>15081.0</td>\n",
       "      <td>9472.5</td>\n",
       "      <td>11916.0</td>\n",
       "      <td>9558.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8576.5</td>\n",
       "      <td>9311.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.117235</td>\n",
       "      <td>-0.114244</td>\n",
       "      <td>1.104472</td>\n",
       "      <td>1.085641</td>\n",
       "      <td>-0.008598</td>\n",
       "      <td>0.236553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-34.096389</td>\n",
       "      <td>24.439167</td>\n",
       "      <td>07-02-2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-32.000556</td>\n",
       "      <td>28.581667</td>\n",
       "      <td>01-10-2014</td>\n",
       "      <td>9125.0</td>\n",
       "      <td>11100.5</td>\n",
       "      <td>9455.0</td>\n",
       "      <td>8711.0</td>\n",
       "      <td>8926.0</td>\n",
       "      <td>9504.0</td>\n",
       "      <td>11166.0</td>\n",
       "      <td>44180.5</td>\n",
       "      <td>-0.017761</td>\n",
       "      <td>0.080052</td>\n",
       "      <td>1.167982</td>\n",
       "      <td>1.174874</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>-0.100586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date      nir    green   swir16   swir22  \\\n",
       "0 -32.043333  27.822778  01-09-2014  15229.0  12868.0  14797.0  12421.0   \n",
       "1 -33.329167  26.077500  16-09-2015      NaN      NaN      NaN      NaN   \n",
       "2 -32.991639  27.640028  07-05-2015  15081.0   9472.5  11916.0   9558.5   \n",
       "3 -34.096389  24.439167  07-02-2012      NaN      NaN      NaN      NaN   \n",
       "4 -32.000556  28.581667  01-10-2014   9125.0  11100.5   9455.0   8711.0   \n",
       "\n",
       "   coastal     blue      red   lwir11      NDMI     MNDWI  Clorfilia  \\\n",
       "0  10961.0  11282.0  13210.0  39652.5  0.014388 -0.069727   1.140578   \n",
       "1      NaN      NaN      NaN      NaN       NaN       NaN        NaN   \n",
       "2      NaN   8576.5   9311.0      NaN  0.117235 -0.114244   1.104472   \n",
       "3      NaN      NaN      NaN      NaN       NaN       NaN        NaN   \n",
       "4   8926.0   9504.0  11166.0  44180.5 -0.017761  0.080052   1.167982   \n",
       "\n",
       "   Turbidity      NDTI      NDVI  \n",
       "0   1.170892  0.013115  0.070994  \n",
       "1        NaN       NaN       NaN  \n",
       "2   1.085641 -0.008598  0.236553  \n",
       "3        NaN       NaN       NaN  \n",
       "4   1.174874  0.002942 -0.100586  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview File\n",
    "landsat_val_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9292c79a",
   "metadata": {},
   "source": [
    "## joining the new features with the example ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c7568fa-6a0e-44c3-8205-a3b8dce27031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas no seu original: 200\n",
      "Linhas no exemplo: 200\n",
      "Linhas ap√≥s a uni√£o: 200\n"
     ]
    }
   ],
   "source": [
    "landsat_example_val_features = pd.read_csv('../Datasets/landsat_features_validation.csv')\n",
    "\n",
    "\n",
    "landsat_val_features['Sample Date'] = pd.to_datetime(landsat_val_features['Sample Date'], dayfirst=True, errors='coerce')\n",
    "landsat_example_val_features['Sample Date'] = pd.to_datetime(landsat_example_val_features['Sample Date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# 2. Definir as colunas que servem de \"ID\" (as chaves)\n",
    "chaves = ['Latitude', 'Longitude', 'Sample Date']\n",
    "\n",
    "# 3. Fazer o merge (Outer Join)\n",
    "# how='outer' garante que:\n",
    "# - Se a linha s√≥ existe no seu, ela fica.\n",
    "# - Se a linha s√≥ existe no exemplo, ela fica.\n",
    "# - Se existe nos dois, elas se juntam.\n",
    "df_merged = pd.merge(\n",
    "    landsat_val_features, \n",
    "    landsat_example_val_features, \n",
    "    on=chaves, \n",
    "    how='outer', \n",
    "    suffixes=('', '_exemplo') # Adiciona sufixo nas colunas repetidas (nir, green, etc)\n",
    ")\n",
    "\n",
    "# 4. Lista das colunas que existem nos dois datasets\n",
    "colunas_comuns = ['nir', 'green', 'swir16', 'swir22', 'NDMI', 'MNDWI']\n",
    "\n",
    "# 5. Preencher os v√°zios: se a coluna original for NaN, pega o valor da coluna _exemplo\n",
    "for col in colunas_comuns:\n",
    "    df_merged[col] = df_merged[col].fillna(df_merged[col + '_exemplo'])\n",
    "\n",
    "df_merged = df_merged.sort_values(by=['Sample Date', 'Latitude', 'Longitude'])\n",
    "df_merged['Sample Date'] = df_merged['Sample Date'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "\n",
    "# 6. Agora que preenchemos, podemos apagar as colunas auxiliares do exemplo\n",
    "colunas_para_remover = [col + '_exemplo' for col in colunas_comuns]\n",
    "df_merged = df_merged.drop(columns=colunas_para_remover)\n",
    "\n",
    "# 7. Verificar o resultado\n",
    "print(f\"Linhas no seu original: {len(landsat_val_features)}\")\n",
    "print(f\"Linhas no exemplo: {len(landsat_example_val_features)}\")\n",
    "print(f\"Linhas ap√≥s a uni√£o: {len(df_merged)}\")\n",
    "\n",
    "# Salvar o resultado final\n",
    "df_merged.to_csv(\"../Datasets/landsat_features_more_bands_val_merged.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
