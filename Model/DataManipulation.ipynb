{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0736224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from HelperFunctions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa90e1",
   "metadata": {},
   "source": [
    "## DADOS terreno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c0408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_use = pd.read_csv(\"../Datasets/soil_use_data_training.csv\")\n",
    "terrain_features = pd.read_csv(\"../Datasets/nasa_terrain_features_training.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964743dc",
   "metadata": {},
   "source": [
    "## Terrain_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d784c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "terrain_features['slope'] = terrain_features['slope'].round(0)\n",
    "terrain_features['curvature'] = terrain_features['curvature'].round(3)\n",
    "\n",
    "terrain_features.to_csv(\"../Datasets/nasa_terrain_features_rounded_training.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4acf929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(terrain_features['slope'].round(0).unique()))\n",
    "print(len(terrain_features['curvature'].round(3).unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da66c16",
   "metadata": {},
   "source": [
    "## soil use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e1233f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pct_agri\n",
      "pct_urban\n",
      "pct_natural\n",
      "pct_water\n",
      "pct_wetlands\n",
      "pct_others\n"
     ]
    }
   ],
   "source": [
    "percentages = [\n",
    "    'pct_agri', 'pct_urban', 'pct_natural', 'pct_water', 'pct_wetlands', 'pct_others'\n",
    "    \n",
    "]\n",
    "\n",
    "for percentage in percentages:\n",
    "    print(percentage)\n",
    "    soil_use[percentage] = soil_use[percentage].round(0)\n",
    "\n",
    "soil_use.to_csv(\"../Datasets/soil_use_data_rounded_training.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d166ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pct_agri\n",
      "47\n",
      "pct_urban\n",
      "27\n",
      "pct_natural\n",
      "59\n",
      "pct_water\n",
      "15\n",
      "pct_wetlands\n",
      "4\n",
      "pct_others\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for percentage in percentages:\n",
    "    print(percentage)\n",
    "    print(len(soil_use[percentage].round(0).unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84789ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_deles = pd.read_csv('../Datasets/landsat_features_training.csv')\n",
    "landsat_meu = pd.read_csv('../Datasets/landsat_features_more_bands_train.csv')\n",
    "terraclimate = pd.read_csv('../Datasets/terraclimate_features_more_bands_training.csv')\n",
    "precip = pd.read_csv('../Datasets/nasa_precip_features_training.csv')\n",
    "terrain = pd.read_csv('../Datasets/nasa_terrain_features_rounded_training.csv')\n",
    "soil_use = pd.read_csv('../Datasets/soil_use_data_rounded_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f636ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ Verificando sincronia das linhas com o gabarito:\n",
      "\n",
      "âœ… landsat_meu: Perfeitamente alinhado.\n",
      "âœ… terraclimate: Perfeitamente alinhado.\n",
      "âœ… precip: Perfeitamente alinhado.\n",
      "âœ… terrain: Perfeitamente alinhado.\n",
      "âœ… soil_use: Perfeitamente alinhado.\n"
     ]
    }
   ],
   "source": [
    "# 1. Carregar os datasets (estou usando os nomes que vocÃª forneceu)\n",
    "datasets = {\n",
    "    'landsat_meu': pd.read_csv('../Datasets/landsat_features_more_bands_train.csv'),\n",
    "    'terraclimate': pd.read_csv('../Datasets/terraclimate_features_more_bands_training.csv'),\n",
    "    'precip': pd.read_csv('../Datasets/nasa_precip_features_training.csv'),\n",
    "    'terrain': pd.read_csv('../Datasets/nasa_terrain_features_rounded_training.csv'),\n",
    "    'soil_use': pd.read_csv('../Datasets/soil_use_data_rounded_training.csv')\n",
    "}\n",
    "\n",
    "gabarito = pd.read_csv('../Datasets/landsat_features_training.csv')\n",
    "\n",
    "def verificar_alinhamento(base_df, target_df, name):\n",
    "    # Verificar se o tamanho Ã© igual\n",
    "    if len(base_df) != len(target_df):\n",
    "        return f\"âŒ {name}: TAMANHO DIFERENTE! ({len(base_df)} vs {len(target_df)})\"\n",
    "    \n",
    "    # Arredondar para evitar erro de precisÃ£o de float (6 casas decimais)\n",
    "    lat_match = np.isclose(base_df['Latitude'], target_df['Latitude'], atol=1e-6)\n",
    "    lon_match = np.isclose(base_df['Longitude'], target_df['Longitude'], atol=1e-6)\n",
    "    \n",
    "    total_desalinhado = np.sum(~(lat_match & lon_match))\n",
    "    \n",
    "    if total_desalinhado == 0:\n",
    "        return f\"âœ… {name}: Perfeitamente alinhado.\"\n",
    "    else:\n",
    "        primeiro_erro = np.where(~(lat_match & lon_match))[0][0]\n",
    "        return f\"âŒ {name}: DESALINHADO! {total_desalinhado} linhas nÃ£o batem. Primeiro erro na linha {primeiro_erro}.\"\n",
    "\n",
    "print(\"ğŸ§ Verificando sincronia das linhas com o gabarito:\\n\")\n",
    "for nome, df in datasets.items():\n",
    "    resultado = verificar_alinhamento(gabarito, df, nome)\n",
    "    print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0e32f",
   "metadata": {},
   "source": [
    "## testando helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b72be923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Carregando dados no DataOrganizer...\n",
      "\n",
      "--- ğŸ§ª TESTES DE INTEGRIDADE ---\n",
      "âœ… Tamanho do Dataset: OK (9319 linhas)\n",
      "âœ… Sincronia das Chaves (Lat/Lon): OK\n",
      "âœ… Alinhamento Feature -> Target: OK\n",
      "âœ… Limpeza de Colunas: OK (Nenhum ID vazou para o treino)\n",
      "\n",
      "ğŸ“‹ Total de features sendo usadas: 29\n",
      "Primeiras 5 features: ['nir', 'green', 'swir16', 'swir22', 'coastal']\n"
     ]
    }
   ],
   "source": [
    "csv_training_files = ['../Datasets/landsat_features_more_bands_train.csv',\n",
    "                          '../Datasets/terraclimate_features_more_bands_training.csv',\n",
    "                          '../Datasets/nasa_precip_features_training.csv',\n",
    "                          '../Datasets/soil_use_data_rounded_training.csv',\n",
    "                          '../Datasets/nasa_terrain_features_rounded_training.csv',\n",
    "                          '../Datasets/water_quality_training_dataset.csv']\n",
    "\n",
    "# 1. Configurar o ambiente de teste\n",
    "# Carregue o arquivo de alvos original para servir de gabarito\n",
    "target_gabarito = pd.read_csv('../Datasets/water_quality_training_dataset.csv')\n",
    "\n",
    "# Instanciar o seu DataOrganizer\n",
    "target_cols = ['Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']\n",
    "drop_cols = ['tmax', 'tmin', 'pct_urban', 'pct_water', 'pct_wetlands', 'pct_others', 'curvature', 'pet']\n",
    "\n",
    "organizer = DataOrganizer(target_cols)\n",
    "\n",
    "# 2. Rodar o carregamento\n",
    "print(\"ğŸ”„ Carregando dados no DataOrganizer...\")\n",
    "organizer.load_training_data(csv_training_files, drop_cols, scale=False)\n",
    "\n",
    "# 3. Extrair os dados processados internamente\n",
    "full_df = organizer.get_full_training_dataset()\n",
    "features, targets = organizer.get_training_dataset()\n",
    "\n",
    "print(\"\\n--- ğŸ§ª TESTES DE INTEGRIDADE ---\")\n",
    "\n",
    "# TESTE 1: VerificaÃ§Ã£o de Tamanho\n",
    "if len(full_df) == len(target_gabarito):\n",
    "    print(f\"âœ… Tamanho do Dataset: OK ({len(full_df)} linhas)\")\n",
    "else:\n",
    "    print(f\"âŒ Tamanho do Dataset: ERRO! ({len(full_df)} vs {len(target_gabarito)})\")\n",
    "\n",
    "# TESTE 2: VerificaÃ§Ã£o de Sincronia de Chaves (Latitude/Longitude)\n",
    "# Vamos comparar o full_dataset interno com o arquivo original de alvos linha a linha\n",
    "lat_match = np.isclose(full_df['Latitude'].values, target_gabarito['Latitude'].values, atol=1e-6)\n",
    "lon_match = np.isclose(full_df['Longitude'].values, target_gabarito['Longitude'].values, atol=1e-6)\n",
    "desalinhados = np.sum(~(lat_match & lon_match))\n",
    "\n",
    "if desalinhados == 0:\n",
    "    print(\"âœ… Sincronia das Chaves (Lat/Lon): OK\")\n",
    "else:\n",
    "    print(f\"âŒ Sincronia das Chaves (Lat/Lon): ERRO! {desalinhados} linhas desalinhadas.\")\n",
    "\n",
    "# TESTE 3: VerificaÃ§Ã£o de Alinhamento Features -> Targets\n",
    "# Verifica se o target na linha X do organizer Ã© o mesmo do arquivo original\n",
    "target_check = np.isclose(targets['Total Alkalinity'].values, target_gabarito['Total Alkalinity'].values, atol=1e-4)\n",
    "if np.all(target_check):\n",
    "    print(\"âœ… Alinhamento Feature -> Target: OK\")\n",
    "else:\n",
    "    print(f\"âŒ Alinhamento Feature -> Target: ERRO! Os alvos foram misturados.\")\n",
    "\n",
    "# TESTE 4: Vazamento de IDs nas Features\n",
    "# Verifique se as colunas proibidas realmente saÃ­ram\n",
    "proibidas = ['Latitude', 'Longitude', 'Sample Date', 'Year', 'MonthOfYear']\n",
    "detectadas = [col for col in features.columns if col in proibidas]\n",
    "if not detectadas:\n",
    "    print(\"âœ… Limpeza de Colunas: OK (Nenhum ID vazou para o treino)\")\n",
    "else:\n",
    "    print(f\"âŒ Limpeza de Colunas: ERRO! Colunas proibidas detectadas nas features: {detectadas}\")\n",
    "\n",
    "# TESTE 5: VerificaÃ§Ã£o de Ordem das Colunas (ConsistÃªncia)\n",
    "print(f\"\\nğŸ“‹ Total de features sendo usadas: {len(features.columns)}\")\n",
    "print(f\"Primeiras 5 features: {list(features.columns[:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7f58f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit_data_organizer(organizer, original_target_path):\n",
    "    print(\"ğŸ” Iniciando Auditoria de SequÃªncia de Coordenadas...\")\n",
    "    \n",
    "    # 1. Carregar o gabarito original (A ordem real que a plataforma espera)\n",
    "    df_gabarito = pd.read_csv(original_target_path)\n",
    "    gabarito_coords = df_gabarito[['Latitude', 'Longitude']].values\n",
    "    \n",
    "    # 2. Verificar o dataset interno completo\n",
    "    full_df = organizer.get_full_training_dataset()\n",
    "    internal_coords = full_df[['Latitude', 'Longitude']].values\n",
    "    \n",
    "    # 3. Verificar o dataset de Features (X) e Targets (Y)\n",
    "    features, targets_dict = organizer.get_training_dataset()\n",
    "    # Como as features nÃ£o tÃªm Lat/Lon, usamos o index para buscar no full_df\n",
    "    x_coords = full_df.loc[features.index, ['Latitude', 'Longitude']].values\n",
    "    \n",
    "    # FunÃ§Ã£o auxiliar para comparar matrizes de coordenadas\n",
    "    def compare_coords(arr1, arr2, label):\n",
    "        if arr1.shape != arr2.shape:\n",
    "            print(f\"âŒ {label}: TAMANHOS DIFERENTES! {arr1.shape} vs {arr2.shape}\")\n",
    "            return False\n",
    "        \n",
    "        # Compara com tolerÃ¢ncia para floats\n",
    "        mismatch = ~np.isclose(arr1, arr2, atol=1e-6).all(axis=1)\n",
    "        count_errors = np.sum(mismatch)\n",
    "        \n",
    "        if count_errors == 0:\n",
    "            print(f\"âœ… {label}: SequÃªncia idÃªntica.\")\n",
    "            return True\n",
    "        else:\n",
    "            first_error = np.where(mismatch)[0][0]\n",
    "            print(f\"âŒ {label}: DESALINHADO! {count_errors} linhas falharam.\")\n",
    "            print(f\"   Primeiro erro no Ã­ndice {first_error}:\")\n",
    "            print(f\"   Esperado: {arr1[first_error]}, Obtido: {arr2[first_error]}\")\n",
    "            return False\n",
    "\n",
    "    # Executar comparaÃ§Ãµes\n",
    "    c1 = compare_coords(gabarito_coords, internal_coords, \"Gabarito vs Dataset Interno\")\n",
    "    c2 = compare_coords(internal_coords, x_coords, \"Dataset Interno vs Features (X)\")\n",
    "    \n",
    "    # Verificar se os Targets batem individualmente\n",
    "    for target_name, target_series in targets_dict.items():\n",
    "        # Como target_series Ã© uma sÃ©rie, o index deve bater com o full_df\n",
    "        target_coords = full_df.loc[target_series.index, ['Latitude', 'Longitude']].values\n",
    "        compare_coords(internal_coords, target_coords, f\"Dataset Interno vs Target ({target_name})\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd425fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Iniciando Auditoria de SequÃªncia de Coordenadas...\n",
      "âœ… Gabarito vs Dataset Interno: SequÃªncia idÃªntica.\n",
      "âœ… Dataset Interno vs Features (X): SequÃªncia idÃªntica.\n",
      "âœ… Dataset Interno vs Target (Total Alkalinity): SequÃªncia idÃªntica.\n",
      "âœ… Dataset Interno vs Target (Electrical Conductance): SequÃªncia idÃªntica.\n",
      "âœ… Dataset Interno vs Target (Dissolved Reactive Phosphorus): SequÃªncia idÃªntica.\n"
     ]
    }
   ],
   "source": [
    "dataHandler = DataOrganizer(target_cols)\n",
    "dataHandler.load_training_data(csv_training_files, drop_cols, scale=False)\n",
    "\n",
    "audit_data_organizer(dataHandler, '../Datasets/water_quality_training_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
