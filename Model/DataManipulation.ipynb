{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0736224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from HelperFunctions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa90e1",
   "metadata": {},
   "source": [
    "## DADOS terreno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c0408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_use = pd.read_csv(\"../Datasets/soil_use_data_training.csv\")\n",
    "terrain_features = pd.read_csv(\"../Datasets/nasa_terrain_features_training.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964743dc",
   "metadata": {},
   "source": [
    "## Terrain_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d784c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "terrain_features['slope'] = terrain_features['slope'].round(0)\n",
    "terrain_features['curvature'] = terrain_features['curvature'].round(3)\n",
    "\n",
    "terrain_features.to_csv(\"../Datasets/nasa_terrain_features_rounded_training.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4acf929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(terrain_features['slope'].round(0).unique()))\n",
    "print(len(terrain_features['curvature'].round(3).unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da66c16",
   "metadata": {},
   "source": [
    "## soil use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e1233f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pct_agri\n",
      "pct_urban\n",
      "pct_natural\n",
      "pct_water\n",
      "pct_wetlands\n",
      "pct_others\n"
     ]
    }
   ],
   "source": [
    "percentages = [\n",
    "    'pct_agri', 'pct_urban', 'pct_natural', 'pct_water', 'pct_wetlands', 'pct_others'\n",
    "    \n",
    "]\n",
    "\n",
    "for percentage in percentages:\n",
    "    print(percentage)\n",
    "    soil_use[percentage] = soil_use[percentage].round(0)\n",
    "\n",
    "soil_use.to_csv(\"../Datasets/soil_use_data_rounded_training.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d166ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pct_agri\n",
      "47\n",
      "pct_urban\n",
      "27\n",
      "pct_natural\n",
      "59\n",
      "pct_water\n",
      "15\n",
      "pct_wetlands\n",
      "4\n",
      "pct_others\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for percentage in percentages:\n",
    "    print(percentage)\n",
    "    print(len(soil_use[percentage].round(0).unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84789ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_deles = pd.read_csv('../Datasets/landsat_features_training.csv')\n",
    "landsat_meu = pd.read_csv('../Datasets/landsat_features_more_bands_train.csv')\n",
    "terraclimate = pd.read_csv('../Datasets/terraclimate_features_more_bands_training.csv')\n",
    "precip = pd.read_csv('../Datasets/nasa_precip_features_training.csv')\n",
    "terrain = pd.read_csv('../Datasets/nasa_terrain_features_rounded_training.csv')\n",
    "soil_use = pd.read_csv('../Datasets/soil_use_data_rounded_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f636ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßê Verificando sincronia das linhas com o gabarito:\n",
      "\n",
      "‚úÖ landsat_meu: Perfeitamente alinhado.\n",
      "‚úÖ terraclimate: Perfeitamente alinhado.\n",
      "‚úÖ precip: Perfeitamente alinhado.\n",
      "‚úÖ terrain: Perfeitamente alinhado.\n",
      "‚úÖ soil_use: Perfeitamente alinhado.\n"
     ]
    }
   ],
   "source": [
    "# 1. Carregar os datasets (estou usando os nomes que voc√™ forneceu)\n",
    "datasets = {\n",
    "    'landsat_meu': pd.read_csv('../Datasets/landsat_features_more_bands_train.csv'),\n",
    "    'terraclimate': pd.read_csv('../Datasets/terraclimate_features_more_bands_training.csv'),\n",
    "    'precip': pd.read_csv('../Datasets/nasa_precip_features_training.csv'),\n",
    "    'terrain': pd.read_csv('../Datasets/nasa_terrain_features_rounded_training.csv'),\n",
    "    'soil_use': pd.read_csv('../Datasets/soil_use_data_rounded_training.csv')\n",
    "}\n",
    "\n",
    "gabarito = pd.read_csv('../Datasets/landsat_features_training.csv')\n",
    "\n",
    "def verificar_alinhamento(base_df, target_df, name):\n",
    "    # Verificar se o tamanho √© igual\n",
    "    if len(base_df) != len(target_df):\n",
    "        return f\"‚ùå {name}: TAMANHO DIFERENTE! ({len(base_df)} vs {len(target_df)})\"\n",
    "    \n",
    "    # Arredondar para evitar erro de precis√£o de float (6 casas decimais)\n",
    "    lat_match = np.isclose(base_df['Latitude'], target_df['Latitude'], atol=1e-6)\n",
    "    lon_match = np.isclose(base_df['Longitude'], target_df['Longitude'], atol=1e-6)\n",
    "    \n",
    "    total_desalinhado = np.sum(~(lat_match & lon_match))\n",
    "    \n",
    "    if total_desalinhado == 0:\n",
    "        return f\"‚úÖ {name}: Perfeitamente alinhado.\"\n",
    "    else:\n",
    "        primeiro_erro = np.where(~(lat_match & lon_match))[0][0]\n",
    "        return f\"‚ùå {name}: DESALINHADO! {total_desalinhado} linhas n√£o batem. Primeiro erro na linha {primeiro_erro}.\"\n",
    "\n",
    "print(\"üßê Verificando sincronia das linhas com o gabarito:\\n\")\n",
    "for nome, df in datasets.items():\n",
    "    resultado = verificar_alinhamento(gabarito, df, nome)\n",
    "    print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0e32f",
   "metadata": {},
   "source": [
    "## testando helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b72be923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Carregando dados no DataOrganizer...\n",
      "\n",
      "--- üß™ TESTES DE INTEGRIDADE ---\n",
      "‚úÖ Tamanho do Dataset: OK (9319 linhas)\n",
      "‚úÖ Sincronia das Chaves (Lat/Lon): OK\n",
      "‚úÖ Alinhamento Feature -> Target: OK\n",
      "‚úÖ Limpeza de Colunas: OK (Nenhum ID vazou para o treino)\n",
      "\n",
      "üìã Total de features sendo usadas: 29\n",
      "Primeiras 5 features: ['nir', 'green', 'swir16', 'swir22', 'coastal']\n"
     ]
    }
   ],
   "source": [
    "csv_training_files = ['../Datasets/landsat_features_more_bands_train.csv',\n",
    "                          '../Datasets/terraclimate_features_more_bands_training.csv',\n",
    "                          '../Datasets/nasa_precip_features_training.csv',\n",
    "                          '../Datasets/soil_use_data_rounded_training.csv',\n",
    "                          '../Datasets/nasa_terrain_features_rounded_training.csv',\n",
    "                          '../Datasets/water_quality_training_dataset.csv']\n",
    "\n",
    "# 1. Configurar o ambiente de teste\n",
    "# Carregue o arquivo de alvos original para servir de gabarito\n",
    "target_gabarito = pd.read_csv('../Datasets/water_quality_training_dataset.csv')\n",
    "\n",
    "# Instanciar o seu DataOrganizer\n",
    "target_cols = ['Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']\n",
    "drop_cols = ['tmax', 'tmin', 'pct_urban', 'pct_water', 'pct_wetlands', 'pct_others', 'curvature', 'pet']\n",
    "\n",
    "organizer = DataOrganizer(target_cols)\n",
    "\n",
    "# 2. Rodar o carregamento\n",
    "print(\"üîÑ Carregando dados no DataOrganizer...\")\n",
    "organizer.load_training_data(csv_training_files, drop_cols, scale=False)\n",
    "\n",
    "# 3. Extrair os dados processados internamente\n",
    "full_df = organizer.get_full_training_dataset()\n",
    "features, targets = organizer.get_training_dataset()\n",
    "\n",
    "print(\"\\n--- üß™ TESTES DE INTEGRIDADE ---\")\n",
    "\n",
    "# TESTE 1: Verifica√ß√£o de Tamanho\n",
    "if len(full_df) == len(target_gabarito):\n",
    "    print(f\"‚úÖ Tamanho do Dataset: OK ({len(full_df)} linhas)\")\n",
    "else:\n",
    "    print(f\"‚ùå Tamanho do Dataset: ERRO! ({len(full_df)} vs {len(target_gabarito)})\")\n",
    "\n",
    "# TESTE 2: Verifica√ß√£o de Sincronia de Chaves (Latitude/Longitude)\n",
    "# Vamos comparar o full_dataset interno com o arquivo original de alvos linha a linha\n",
    "lat_match = np.isclose(full_df['Latitude'].values, target_gabarito['Latitude'].values, atol=1e-6)\n",
    "lon_match = np.isclose(full_df['Longitude'].values, target_gabarito['Longitude'].values, atol=1e-6)\n",
    "desalinhados = np.sum(~(lat_match & lon_match))\n",
    "\n",
    "if desalinhados == 0:\n",
    "    print(\"‚úÖ Sincronia das Chaves (Lat/Lon): OK\")\n",
    "else:\n",
    "    print(f\"‚ùå Sincronia das Chaves (Lat/Lon): ERRO! {desalinhados} linhas desalinhadas.\")\n",
    "\n",
    "# TESTE 3: Verifica√ß√£o de Alinhamento Features -> Targets\n",
    "# Verifica se o target na linha X do organizer √© o mesmo do arquivo original\n",
    "target_check = np.isclose(targets['Total Alkalinity'].values, target_gabarito['Total Alkalinity'].values, atol=1e-4)\n",
    "if np.all(target_check):\n",
    "    print(\"‚úÖ Alinhamento Feature -> Target: OK\")\n",
    "else:\n",
    "    print(f\"‚ùå Alinhamento Feature -> Target: ERRO! Os alvos foram misturados.\")\n",
    "\n",
    "# TESTE 4: Vazamento de IDs nas Features\n",
    "# Verifique se as colunas proibidas realmente sa√≠ram\n",
    "proibidas = ['Latitude', 'Longitude', 'Sample Date', 'Year', 'MonthOfYear']\n",
    "detectadas = [col for col in features.columns if col in proibidas]\n",
    "if not detectadas:\n",
    "    print(\"‚úÖ Limpeza de Colunas: OK (Nenhum ID vazou para o treino)\")\n",
    "else:\n",
    "    print(f\"‚ùå Limpeza de Colunas: ERRO! Colunas proibidas detectadas nas features: {detectadas}\")\n",
    "\n",
    "# TESTE 5: Verifica√ß√£o de Ordem das Colunas (Consist√™ncia)\n",
    "print(f\"\\nüìã Total de features sendo usadas: {len(features.columns)}\")\n",
    "print(f\"Primeiras 5 features: {list(features.columns[:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7f58f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit_data_organizer(organizer, original_target_path):\n",
    "    print(\"üîé Iniciando Auditoria de Sequ√™ncia de Coordenadas...\")\n",
    "    \n",
    "    # 1. Carregar o gabarito original (A ordem real que a plataforma espera)\n",
    "    df_gabarito = pd.read_csv(original_target_path)\n",
    "    gabarito_coords = df_gabarito[['Latitude', 'Longitude']].values\n",
    "    \n",
    "    # 2. Verificar o dataset interno completo\n",
    "    full_df = organizer.get_full_training_dataset()\n",
    "    internal_coords = full_df[['Latitude', 'Longitude']].values\n",
    "    \n",
    "    # 3. Verificar o dataset de Features (X) e Targets (Y)\n",
    "    features, targets_dict = organizer.get_training_dataset()\n",
    "    # Como as features n√£o t√™m Lat/Lon, usamos o index para buscar no full_df\n",
    "    x_coords = full_df.loc[features.index, ['Latitude', 'Longitude']].values\n",
    "    \n",
    "    # Fun√ß√£o auxiliar para comparar matrizes de coordenadas\n",
    "    def compare_coords(arr1, arr2, label):\n",
    "        if arr1.shape != arr2.shape:\n",
    "            print(f\"‚ùå {label}: TAMANHOS DIFERENTES! {arr1.shape} vs {arr2.shape}\")\n",
    "            return False\n",
    "        \n",
    "        # Compara com toler√¢ncia para floats\n",
    "        mismatch = ~np.isclose(arr1, arr2, atol=1e-6).all(axis=1)\n",
    "        count_errors = np.sum(mismatch)\n",
    "        \n",
    "        if count_errors == 0:\n",
    "            print(f\"‚úÖ {label}: Sequ√™ncia id√™ntica.\")\n",
    "            return True\n",
    "        else:\n",
    "            first_error = np.where(mismatch)[0][0]\n",
    "            print(f\"‚ùå {label}: DESALINHADO! {count_errors} linhas falharam.\")\n",
    "            print(f\"   Primeiro erro no √≠ndice {first_error}:\")\n",
    "            print(f\"   Esperado: {arr1[first_error]}, Obtido: {arr2[first_error]}\")\n",
    "            return False\n",
    "\n",
    "    # Executar compara√ß√µes\n",
    "    c1 = compare_coords(gabarito_coords, internal_coords, \"Gabarito vs Dataset Interno\")\n",
    "    c2 = compare_coords(internal_coords, x_coords, \"Dataset Interno vs Features (X)\")\n",
    "    \n",
    "    # Verificar se os Targets batem individualmente\n",
    "    for target_name, target_series in targets_dict.items():\n",
    "        # Como target_series √© uma s√©rie, o index deve bater com o full_df\n",
    "        target_coords = full_df.loc[target_series.index, ['Latitude', 'Longitude']].values\n",
    "        compare_coords(internal_coords, target_coords, f\"Dataset Interno vs Target ({target_name})\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd425fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Iniciando Auditoria de Sequ√™ncia de Coordenadas...\n",
      "‚úÖ Gabarito vs Dataset Interno: Sequ√™ncia id√™ntica.\n",
      "‚úÖ Dataset Interno vs Features (X): Sequ√™ncia id√™ntica.\n",
      "‚úÖ Dataset Interno vs Target (Total Alkalinity): Sequ√™ncia id√™ntica.\n",
      "‚úÖ Dataset Interno vs Target (Electrical Conductance): Sequ√™ncia id√™ntica.\n",
      "‚úÖ Dataset Interno vs Target (Dissolved Reactive Phosphorus): Sequ√™ncia id√™ntica.\n"
     ]
    }
   ],
   "source": [
    "dataHandler = DataOrganizer(target_cols)\n",
    "dataHandler.load_training_data(csv_training_files, drop_cols, scale=False)\n",
    "\n",
    "audit_data_organizer(dataHandler, '../Datasets/water_quality_training_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216abd74",
   "metadata": {},
   "source": [
    "## fazendo caracteristicas do solo serem em \"packs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d9d325b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Latitude', 'Longitude', 'Sample Date', 'pct_agri', 'pct_urban',\n",
       "       'pct_natural', 'pct_water', 'pct_wetlands', 'pct_others'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solo = pd.read_csv('../Datasets/soil_use_data_rounded_training.csv')\n",
    "solo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5587aa82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Latitude        -34.405833\n",
       "Longitude        17.730278\n",
       "Sample Date     01-01-2013\n",
       "pct_agri               0.0\n",
       "pct_urban              0.0\n",
       "pct_natural            3.0\n",
       "pct_water              0.0\n",
       "pct_wetlands           0.0\n",
       "pct_others             0.0\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solo.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75168fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Latitude        -22.225556\n",
       "Longitude           32.325\n",
       "Sample Date     31-12-2015\n",
       "pct_agri              86.0\n",
       "pct_urban             60.0\n",
       "pct_natural          100.0\n",
       "pct_water             14.0\n",
       "pct_wetlands          16.0\n",
       "pct_others            92.0\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solo.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4ec07187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pct_agri\n",
      "pct_urban\n",
      "pct_natural\n",
      "pct_water\n",
      "pct_wetlands\n",
      "pct_others\n"
     ]
    }
   ],
   "source": [
    "for coluna in solo.columns:\n",
    "    if coluna not in ['Latitude', 'Longitude', 'Sample Date']:\n",
    "        print(coluna)\n",
    "        solo[coluna] = (solo[coluna] // 10) * 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02c18b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude        -34.405833\n",
      "Longitude        17.730278\n",
      "Sample Date     01-01-2013\n",
      "pct_agri               0.0\n",
      "pct_urban              0.0\n",
      "pct_natural            0.0\n",
      "pct_water              0.0\n",
      "pct_wetlands           0.0\n",
      "pct_others             0.0\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Latitude        -22.225556\n",
       "Longitude           32.325\n",
       "Sample Date     31-12-2015\n",
       "pct_agri              80.0\n",
       "pct_urban             60.0\n",
       "pct_natural          100.0\n",
       "pct_water             10.0\n",
       "pct_wetlands          10.0\n",
       "pct_others            90.0\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(solo.min())\n",
    "solo.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca95e08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pct_agri\n",
      "9\n",
      "pct_urban\n",
      "7\n",
      "pct_natural\n",
      "11\n",
      "pct_water\n",
      "2\n",
      "pct_wetlands\n",
      "2\n",
      "pct_others\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for coluna in solo.columns:\n",
    "    if coluna not in ['Latitude', 'Longitude', 'Sample Date']:\n",
    "        print(coluna)\n",
    "        print(len(solo[coluna].unique()))\n",
    "\n",
    "solo.to_csv('../Datasets/soil_use_data_rounded_in_packs_training.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e337e978",
   "metadata": {},
   "source": [
    "## Terrain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "da27eb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Latitude', 'Longitude', 'Sample Date', 'elevation', 'slope',\n",
       "       'curvature'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terrain = pd.read_csv('../Datasets/nasa_terrain_features_rounded_training.csv')\n",
    "\n",
    "terrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f27fa299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Latitude       -34.405833\n",
       "Longitude       17.730278\n",
       "Sample Date    01-01-2013\n",
       "elevation             5.0\n",
       "slope                 0.0\n",
       "curvature          -0.003\n",
       "dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terrain.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9e8910e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Latitude       -22.225556\n",
       "Longitude          32.325\n",
       "Sample Date    31-12-2015\n",
       "elevation          1594.0\n",
       "slope                28.0\n",
       "curvature           0.014\n",
       "dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terrain.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "021b31c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elevation\n",
      "148\n",
      "slope\n",
      "18\n",
      "curvature\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for coluna in terrain.columns:\n",
    "    if coluna not in ['Latitude', 'Longitude', 'Sample Date']:\n",
    "        print(coluna)\n",
    "        print(len(terrain[coluna].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6868deaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Latitude       -34.405833\n",
      "Longitude       17.730278\n",
      "Sample Date    01-01-2013\n",
      "elevation             0.0\n",
      "slope                 0.0\n",
      "curvature          -0.003\n",
      "dtype: object\n",
      "\n",
      "Latitude       -22.225556\n",
      "Longitude          32.325\n",
      "Sample Date    31-12-2015\n",
      "elevation          1540.0\n",
      "slope                28.0\n",
      "curvature           0.012\n",
      "dtype: object\n",
      "\n",
      "elevation\n",
      "15\n",
      "slope\n",
      "11\n",
      "curvature\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "terrain['elevation'] = (terrain['elevation'] // 110) * 110\n",
    "terrain['slope'] = (terrain['slope'] // 2) * 2\n",
    "terrain['curvature'] = (terrain['curvature'] // 0.003) * 0.003\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "print(terrain.min())\n",
    "print()\n",
    "print(terrain.max())\n",
    "print()\n",
    "\n",
    "for coluna in terrain.columns:\n",
    "    if coluna not in ['Latitude', 'Longitude', 'Sample Date']:\n",
    "        print(coluna)\n",
    "        print(len(terrain[coluna].unique()))\n",
    "\n",
    "\n",
    "terrain.to_csv('../Datasets/nasa_terrain_features_rounded_in_packs_training.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
